{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# Packages #\n",
    "############\n",
    "import time as t\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import scipy as sp\n",
    "\n",
    "###################\n",
    "# hyperparametres #\n",
    "###################\n",
    "\n",
    "# for reproductibility\n",
    "seed = 0\n",
    "\n",
    "# data dimensions\n",
    "T=200\n",
    "k=100\n",
    "l =0\n",
    "\n",
    "#Z : (k,1)\n",
    "#Y : (T,1)\n",
    "#U : (T,l)\n",
    "#X : (T,k)\n",
    "\n",
    "# data generations\n",
    "\n",
    "# for X:\n",
    "rho=0.75\n",
    "\n",
    "# for Beta : number of non null\n",
    "s=5 #in [5,10,100]\n",
    "lst_s = [5,10,100]\n",
    "\n",
    "# for sigma2 :ratio between explained and total variance \n",
    "Ry=0.02 #in [0.02, 0.25, 0.5]\n",
    "lst_Ry = [0.02, 0.25, 0.5]\n",
    "\n",
    "# for q prior\n",
    "a=1\n",
    "b=1\n",
    "\n",
    "# for R2 prior\n",
    "A=1\n",
    "B=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters\n",
    "\n",
    "Firstly, let's comput the initialization of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_X(T, k, rho):\n",
    "    \"\"\"Compute matrix of xt observations\n",
    "\n",
    "    Args:\n",
    "        T (int): number of observations\n",
    "        k (int): number of predictors\n",
    "        rho (float): Toeplitz correlation parameter\n",
    "\n",
    "    Returns:\n",
    "        np.array: dimensions T*k\n",
    "    \"\"\"\n",
    "    cov_matrix=np.zeros((k, k))\n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            cov_matrix[i,j]=rho**np.abs(i-j)\n",
    "    return np.random.multivariate_normal([0]*k, cov_matrix, T)\n",
    "\n",
    "def compute_U(T, l):\n",
    "    \"\"\"Compute matrix of xt observations\n",
    "\n",
    "    Args:\n",
    "        T (int): number of observations\n",
    "        l (int): number of predictors\n",
    "\n",
    "    Returns:\n",
    "        np.array: dimensions T*l\n",
    "    \"\"\"\n",
    "    if l==0:\n",
    "        return 0\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "def compute_vx(X):\n",
    "    return np.mean(np.var(X,axis=0))\n",
    "\n",
    "def sample_beta(k, s):\n",
    "    \"\"\"Sample of beta vector of dimensions 1*k\n",
    "\n",
    "    Args:\n",
    "        k (int): number of predictors\n",
    "        s (int): number of non-zero elements of beta\n",
    "\n",
    "    Returns:\n",
    "        np.array: dimensions 1*k\n",
    "    \"\"\"\n",
    "    beta=np.zeros(k)\n",
    "    index_normal_distribution=np.random.choice(len(beta), size=s, replace=False)\n",
    "    beta[index_normal_distribution] = np.random.normal(loc=0, scale=1, size=s)\n",
    "    return beta\n",
    "\n",
    "def sample_phi(l):\n",
    "    if l==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.random.uniform(0,1, size=l)\n",
    "\n",
    "def comput_Z(beta):\n",
    "    \"\"\"Compute z_1,...,z_k\n",
    "\n",
    "    Args:\n",
    "        beta (np.array): random vector beta\n",
    "\n",
    "    Returns:\n",
    "        np.array: dimensions1*k\n",
    "    \"\"\"\n",
    "    Z=beta\n",
    "    Z[Z!=0]=1\n",
    "    return Z\n",
    "\n",
    "def compute_sigma2(Ry, beta, X):\n",
    "    \"\"\" Compute sigma2\n",
    "    Args:\n",
    "        Ry (float): pourcentage of explained variance\n",
    "        beta (np.array): beta previously sampled\n",
    "        X (np.array): matrix of (xt) samples\n",
    "\n",
    "    Returns:\n",
    "        float: dimensions 1*1\n",
    "    \"\"\"\n",
    "    return (1/Ry-1)*np.mean(np.square(X @ beta))\n",
    "\n",
    "def compute_R2(q, k, gamma2, v_x):\n",
    "    return (q*k*gamma2*v_x)/(q*k*gamma2*v_x+1)\n",
    "\n",
    "def sample_epsilon(T, sigma2):\n",
    "    \"\"\"Sample epsilon_1,...,epsilon_T\n",
    "\n",
    "    Args:\n",
    "        T (int): number of observations\n",
    "        sigma2 (float): sigma2 previously sampled\n",
    "\n",
    "    Returns:\n",
    "        np.array: dimensions 1*T\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc=0, scale=sigma2, size=T)\n",
    "\n",
    "def compute_Y(X, beta, epsilon):\n",
    "    return X@beta + epsilon\n",
    "\n",
    "\n",
    "### Final function\n",
    "def init_parameters(seed, T, k, l, rho, s, Ry, a, b, A, B):\n",
    "    \"\"\"\n",
    "    Initialize parameters for a given simulation.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed for reproducibility.\n",
    "        T (int): Number of observations.\n",
    "        k (int): Number of covariates.\n",
    "        l (int): Number of latent variables.\n",
    "        rho (float): Correlation parameter.\n",
    "        s (float): Scaling parameter.\n",
    "        Ry (float): Response variance.\n",
    "        a (float): Shape parameter for gamma2.\n",
    "        b (float): Shape parameter for gamma2.\n",
    "        A (float): Shape parameter for q.\n",
    "        B (float): Shape parameter for q.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing initialized parameters.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed=seed)\n",
    "    dct = {\n",
    "        \"X\" : compute_X(T=T, k=k, rho=rho),\n",
    "        \"U\": compute_U(T=T, l=l),\n",
    "        \"beta\": sample_beta(k=k, s=s),\n",
    "        \"phi\": sample_phi(l=l),\n",
    "        \"q\": np.random.beta(A,B),\n",
    "        \"gamma2\": np.random.beta(a,b),\n",
    "    }\n",
    "    dct[\"vx\"] = compute_vx(X=dct[\"X\"])\n",
    "    dct[\"R2\"] = compute_R2(q=dct[\"q\"], k=k, gamma2=dct[\"gamma2\"], v_x=dct[\"vx\"])\n",
    "    dct[\"Z\"]=comput_Z(beta=dct[\"beta\"])\n",
    "    dct[\"sigma2\"] = compute_sigma2(Ry=Ry, beta=dct[\"beta\"], X=dct[\"X\"])\n",
    "    dct[\"epsilon\"] = sample_epsilon(T=T, sigma2=dct[\"sigma2\"])\n",
    "    dct[\"Y\"]=compute_Y(X=dct[\"X\"], beta=dct[\"beta\"], epsilon=dct[\"epsilon\"])\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = init_parameters(seed,T,k,l,rho,s,Ry,a,b,A,B)\n",
    "\n",
    "# for scalar in [\"q\", \"gamma2\", \"vx\", \"R2\", \"sigma2\"]:\n",
    "#     value = dct[scalar]\n",
    "#     print(f\"{scalar}={value}\\n\")\n",
    "\n",
    "# for mat in [\"beta\", \"phi\", \"Y\", \"epsilon\", \"X\", \"U\"]:\n",
    "#     value = dct[mat]\n",
    "#     fig = px.histogram(value, histnorm='probability density', title = f\"<b>Histogram of {mat}</b> shape : {value.shape} \", template=\"plotly_dark\")\n",
    "#     fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples simple discrete variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_discrete(seed, values, weights, n_points):\n",
    "    probs = weights/weights.sum()\n",
    "    return sp.stats.rv_discrete(seed = seed, values = (values, probs)).rvs(size=n_points)\n",
    "\n",
    "#print(sample_discrete(seed, np.arange(3), np.arange(1,4) , 100))\n",
    "\n",
    "def sample_discrete_ndim(seed, values, weights, n_points):\n",
    "    nval = np.multiply(values.shape)\n",
    "    return sample_discrete(seed, values.reshape(nval), weights.reshape(nval), n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 22 20 ... 23  3 24]\n"
     ]
    }
   ],
   "source": [
    "test_multy_sample = sample_discrete(seed, np.arange(27).reshape((3,3,3)), np.arange(1,28).reshape((3,3,3)) , 10000)\n",
    "print(test_multy_sample)\n",
    "# fig = px.histogram(test_multy_sample, histnorm='probability density', title = f\"<b>Histogram from a linear 3D density</b>\", template=\"plotly_dark\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Draw from the conditional posterior of (R2, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_unormalized_R2_q_by_Y_U_X_theta_z(R2, q, dct, k, a, b, A, B):\n",
    "    vx = dct[\"vx\"]\n",
    "    s_z = np.sum(dct[\"Z\"])\n",
    "    sigma2 = dct[\"sigma2\"]\n",
    "    Beta = dct[\"beta\"]\n",
    "    exponent = - np.prod([\n",
    "        1/(1e-6 + 2*sigma2),\n",
    "        (k*vx*q*(1-R2))/(1e-6 + R2),\n",
    "         np.dot(Beta, np.dot(np.diag(dct[\"Z\"]), Beta))\n",
    "        ])       \n",
    "    return np.prod([\n",
    "        np.exp(exponent),\n",
    "        q**(s_z+s_z/2+a-1),\n",
    "        (1-q)**(k-s_z+b-1),\n",
    "        R2**(A-1-s_z/2),\n",
    "        (1-R2)**(s_z/2+B-1)\n",
    "    ])\n",
    "\n",
    "def sample_R2_q_by_Y_U_X_theta_z(seed, n_points, dct, k, a, b, A, B):\n",
    "    \n",
    "    arr0 = np.arange(0.001,0.101,0.001) # commence pas à 0 car division par 0 sinon\n",
    "    arr1 = np.arange(0.11,0.91,0.01)\n",
    "    arr2 = np.arange(0.901,1.001,0.001)\n",
    "    discretization = np.concatenate((arr0, arr1, arr2), axis=0)\n",
    "    \n",
    "    values = np.dstack(np.meshgrid(discretization, discretization)).reshape(-1, 2)\n",
    "    def density(R2_q):\n",
    "        R2 = R2_q[0]\n",
    "        q = R2_q[1]\n",
    "        return density_unormalized_R2_q_by_Y_U_X_theta_z(R2, q, dct, k, a, b, A, B)\n",
    "    \n",
    "    weights = np.apply_along_axis(density, 1, values) \n",
    "    index = np.arange(len(weights))\n",
    "    sample_mask = sample_discrete(seed, index, weights, n_points)\n",
    "    return values[sample_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.028 0.063]\n",
      " [0.018 0.073]]\n"
     ]
    }
   ],
   "source": [
    "posterior_R2_q=sample_R2_q_by_Y_U_X_theta_z(seed=seed, n_points=2, dct=dct, k=k, a=a, b=b, A=A, B=B)\n",
    "print(posterior_R2_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=dct['Z']\n",
    "X=dct['X']\n",
    "U=dct['U']\n",
    "Y=dct['Y']\n",
    "q=dct[\"q\"]\n",
    "gamma2=dct[\"gamma2\"]\n",
    "beta=dct[\"beta\"]\n",
    "phi=dct[\"phi\"]\n",
    "sigma2=dct[\"sigma2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample from the conditional posterior of $\\phi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_phi_posterior(U, Y, X, beta, sigma2, l, n_variables, seed):\n",
    "    \"\"\"Sample 1*l random vectors ϕ|Y, U, X, z, β, R^2, q, sigma^2\n",
    "\n",
    "    Args:\n",
    "        U (np.array): T*l matrix of predictors\n",
    "        Y (np.array): T*1 vector of target\n",
    "        X (np.array): T*k matrix of predictors\n",
    "        beta (np.array): 1*k vector beta\n",
    "        sigma2 (float): sigma^2\n",
    "        n_variables (int): number of variables\n",
    "        seed (int): seed\n",
    "\n",
    "    Returns:\n",
    "        np.array: n_variables of 1*l random vectors\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    if l==0:\n",
    "        return sample_phi(l=l)\n",
    "    else:\n",
    "        return np.random.multivariate_normal(np.linalg.inv(U.T@U)@U.T@(Y-X@beta), sigma2*np.linalg.inv(U.T@U), n_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "phi_posterior=sample_phi_posterior(U=U, Y=Y, X=X, beta=beta, sigma2=sigma2, l=l, n_variables=2, seed=seed)\n",
    "print(phi_posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sample from the conditional posterior of $z$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary step: compute some random vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_X_tilde(X,beta):\n",
    "    \"\"\"Compute T*s(z) \\Tilde{X} matrix\n",
    "\n",
    "    Args:\n",
    "        X (np.array): T*p matrix of x predictors\n",
    "        beta (np.array): 1*p vector of beta prior\n",
    "\n",
    "    Returns:\n",
    "        np.array: \\Tilde{X} matrix\n",
    "    \"\"\"\n",
    "    non_zero_beta=list(np.nonzero(beta)[0])\n",
    "    X_tilde=X[:, non_zero_beta]\n",
    "    return X_tilde\n",
    "\n",
    "def compute_W_tilde(X_tilde, gamma2):\n",
    "    \"\"\"Compute s(z)*s(z) \\Tilde{W} matrix\n",
    "\n",
    "    Args:\n",
    "        X_tilde (np.array): T*s(z) \\Tilde{X} matrix\n",
    "        gamma2 (float): gamma^2 \n",
    "\n",
    "    Returns:\n",
    "        np.array: \\Tilde{W} matrix\n",
    "    \"\"\"\n",
    "    I_s_z=np.identity(X_tilde.shape[1])\n",
    "    return X_tilde.T@X_tilde+(1/gamma2)*I_s_z\n",
    "\n",
    "def compute_Y_tilde(Y, U, phi):\n",
    "    \"\"\"Compute 1*T \\Tilde{Y} matrix\n",
    "\n",
    "    Args:\n",
    "        Y (np.array): 1*T vector of target variables\n",
    "        U (np.array): T*l matrix of u predictors\n",
    "        phi (np.array): 1*l phi vector\n",
    "\n",
    "    Returns:\n",
    "        np.array: \\Tilde{Y}\n",
    "    \"\"\"\n",
    "    if U==0:\n",
    "        return Y\n",
    "    else:\n",
    "        return Y-U@phi\n",
    "\n",
    "def compute_estimator_beta_tilde(W_tilde, X_tilde, Y_tilde):\n",
    "    \"\"\"Compute 1*s(z) \\hat{\\Tilde{\\beta}} vector\n",
    "\n",
    "    Args:\n",
    "        W_tilde (np.array): s(z)*s(z) \\Tilde{W} matrix\n",
    "        X_tilde (np.array): T*s(z) \\Tilde{X} matrix\n",
    "        Y_tilde (np.array): 1*T \\Tilde{Y} matrix\n",
    "\n",
    "    Returns:\n",
    "        np.array: 1*s(z) \\hat{\\Tilde{\\beta}} vector\n",
    "    \"\"\"\n",
    "    return np.linalg.inv(W_tilde)@X_tilde.T@Y_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_z_posterior(q, k, Z, gamma2, W_tilde, Y_tilde, estimator_beta_tilde, T):\n",
    "    \"\"\"Compute \\pi(z|Y, U, X, \\phi, R^2, q) mass function\n",
    "\n",
    "    Args:\n",
    "        q (float): q variable\n",
    "        k (int): number of x predictors\n",
    "        Z (np.array): 1*k array of z1,...,zk\n",
    "        gamma2 (float): gamma^2 variable\n",
    "        W_tilde (np.array): s(z)*s(z) \\Tilde{W} matrix\n",
    "        Y_tilde (np.array): 1*T \\Tilde{Y} matrix\n",
    "        estimator_beta_tilde (np.array): 1*s(z) \\hat{\\Tilde{\\beta}} vector\n",
    "        T (int): number of samples\n",
    "\n",
    "    Returns:\n",
    "        float: value of \\pi(z|Y, U, X, \\phi, R^2, q)\n",
    "    \"\"\"\n",
    "    s_z=np.sum(Z)\n",
    "    return q**s_z*(1-q)**(k-s_z)*(1/gamma2)**(s_z/2)*np.linalg.det(W_tilde)**(-0.5)*0.5**(-T/2)*(Y_tilde.T@Y_tilde-estimator_beta_tilde.T@W_tilde@estimator_beta_tilde)**(-T/2)*sp.special.gamma(T/2)\n",
    "\n",
    "\n",
    "def compute_zi_posterior_conditional_z_excluded_i(z_i, z_minus_i, i, q, k, gamma2, W_tilde, Y_tilde, estimator_beta_tilde, T):\n",
    "    \"\"\"Compute \\pi(z_i|Y, X, U, \\phi, R^2, q, z_{-i}) for a specific zi\n",
    "\n",
    "    Args:\n",
    "        z_i (int): z_i variable\n",
    "        z_minus_i (np.array): z random vector with z_i excluded\n",
    "        i (int): index of z_i variable in z random vector\n",
    "        q (float): q variable\n",
    "        k (int): number of x predictors\n",
    "        gamma2 (float): gamma^2 variable\n",
    "        W_tilde (np.array): s(z)*s(z) \\Tilde{W} matrix\n",
    "        Y_tilde (np.array): 1*T \\Tilde{Y} matrix\n",
    "        estimator_beta_tilde (np.array): 1*s(z) \\hat{\\Tilde{\\beta}} vector\n",
    "        T (int): number of samples\n",
    "\n",
    "    Returns:\n",
    "        float: value of \\pi(z_i|Y, X, U, \\phi, R^2, q, z_{-i})\n",
    "    \"\"\"\n",
    "\n",
    "    z=z_minus_i\n",
    "    z=np.insert(z, i, z_i)\n",
    "    z_posterior=compute_z_posterior(q=q, k=k, Z=z, gamma2=gamma2, W_tilde=W_tilde, Y_tilde=Y_tilde, estimator_beta_tilde=estimator_beta_tilde, T=T)\n",
    "    z_0=np.copy(z)\n",
    "    z_0[i]=0\n",
    "    z_posterior_zi_equal_0=compute_z_posterior(q=q, k=k, Z=z_0, gamma2=gamma2, W_tilde=W_tilde, Y_tilde=Y_tilde, estimator_beta_tilde=estimator_beta_tilde, T=T)\n",
    "    z_1=np.copy(Z)\n",
    "    z_1[i]=1\n",
    "    z_posterior_zi_equal_1=compute_z_posterior(q=q, k=k, Z=z_1, gamma2=gamma2, W_tilde=W_tilde, Y_tilde=Y_tilde, estimator_beta_tilde=estimator_beta_tilde, T=T)\n",
    "\n",
    "    return z_posterior/(z_posterior_zi_equal_0+z_posterior_zi_equal_1+1e-6)\n",
    "\n",
    "def simulated_zi_posterior_conditional_z_excluded_i(z_minus_i, i, q, k, gamma2, W_tilde, Y_tilde, estimator_beta_tilde, T):\n",
    "    \"\"\"Sample z_i|Y, X, U, \\phi, R^2, q z_{-i}, by inverse CDF method\n",
    "\n",
    "    Args:\n",
    "        z_minus_i (np.array): z random vector with z_i excluded\n",
    "        i (int): index of z_i variable in z random vector\n",
    "        q (float): q variable\n",
    "        k (int): number of x predictors\n",
    "        gamma2 (float): gamma^2 variable\n",
    "        W_tilde (np.array): s(z)*s(z) \\Tilde{W} matrix\n",
    "        Y_tilde (np.array): 1*T \\Tilde{Y} matrix\n",
    "        estimator_beta_tilde (np.array): 1*s(z) \\hat{\\Tilde{\\beta}} vector\n",
    "        T (int): number of samples\n",
    "\n",
    "    Returns:\n",
    "        int: value of z_i|Y, X, U, \\phi, R^2, q z_{-i} in {0,1} \n",
    "    \"\"\"\n",
    "    proba_success=compute_zi_posterior_conditional_z_excluded_i(z_i=1, z_minus_i=z_minus_i, i=i, q=q, k=k, gamma2=gamma2, W_tilde=W_tilde, Y_tilde=Y_tilde, estimator_beta_tilde=estimator_beta_tilde, T=T)\n",
    "    u=np.random.uniform(0,1)\n",
    "    if u<=1-proba_success:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def step_gibbs_sampler_z_posterior(q, k, gamma2, W_tilde, Y_tilde, estimator_beta_tilde, T, z_t_minus_1):\n",
    "    \"\"\"One iteration of Gibbs sampler\n",
    "\n",
    "    Args:\n",
    "        q (float): q variable\n",
    "        k (int): number of x predictors\n",
    "        gamma2 (float): gamma^2 variable\n",
    "        W_tilde (np.array): s(z)*s(z) \\Tilde{W} matrix\n",
    "        Y_tilde (np.array): 1*T \\Tilde{Y} matrix\n",
    "        estimator_beta_tilde (np.array): 1*s(z) \\hat{\\Tilde{\\beta}} vector\n",
    "        T (int): number of samples\n",
    "        z_t_minus_1 (_type_): z_{t-1} variable sampled during the previous iteration (t-1 step)\n",
    "\n",
    "    Returns:\n",
    "        np.array: array of variables Z^(t)=(Z^(t)_1,...,Z^(t)_k) sampled at step t\n",
    "    \"\"\"\n",
    "    z_t=np.copy(z_t_minus_1)\n",
    "    for i in range(len(z_t)):\n",
    "        z_t_minus_i=np.delete(z_t, i)\n",
    "        sampled_z_t_i=simulated_zi_posterior_conditional_z_excluded_i(z_minus_i=z_t_minus_i, i=i, q=q, k=k, gamma2=gamma2, W_tilde=W_tilde, Y_tilde=Y_tilde, estimator_beta_tilde=estimator_beta_tilde, T=T)\n",
    "        z_t=np.insert(z_t_minus_i, i, sampled_z_t_i)\n",
    "    return z_t\n",
    "\n",
    "def gibbs_sampler_z_posterior(q, k, gamma2, W_tilde, Y_tilde, estimator_beta_tilde, T, n_iter, n_variables):\n",
    "    \"\"\"Gibbs sampler to simulate 1*k vectors z|Y, U, X, \\phi, R^2\n",
    "\n",
    "    Args:\n",
    "        q (float): q variable\n",
    "        k (int): number of x predictors\n",
    "        gamma2 (float): gamma^2 variable\n",
    "        W_tilde (np.array): s(z)*s(z) \\Tilde{W} matrix\n",
    "        Y_tilde (np.array): 1*T \\Tilde{Y} matrix\n",
    "        estimator_beta_tilde (np.array): 1*s(z) \\hat{\\Tilde{\\beta}} vector\n",
    "        T (int): number of samples\n",
    "        n_iter (int): number of iterations\n",
    "        n_variables (int): number of variables desired\n",
    "\n",
    "    Returns:\n",
    "        np.array: array of n_variables z=(z_1,...,z_k)\n",
    "    \"\"\"\n",
    "    array_z=[]\n",
    "    for n in range(n_variables):\n",
    "        z_0=np.random.binomial(n=1, p=q, size=k) #Yanis; je ne sais pas trop comment initialiser le premier Z, j'ai repris la loi a priori\n",
    "        z_t=z_0\n",
    "        for t in range(n_iter):\n",
    "            z_t=step_gibbs_sampler_z_posterior(q=q, k=k, gamma2=gamma2, W_tilde=W_tilde, Y_tilde=Y_tilde, estimator_beta_tilde=estimator_beta_tilde, T=T, z_t_minus_1=z_t)\n",
    "        array_z.append(z_t)\n",
    "    return np.array(array_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tilde=compute_X_tilde(X=X,beta=beta)\n",
    "W_tilde=compute_W_tilde(X_tilde=X_tilde, gamma2=gamma2)\n",
    "Y_tilde=compute_Y_tilde(Y=Y, U=U, phi=phi)\n",
    "estimator_beta_tilde=compute_estimator_beta_tilde(W_tilde=W_tilde, X_tilde=X_tilde, Y_tilde=Y_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sample_posterior_z=gibbs_sampler_z_posterior(q=q,\n",
    "                                   k=k, \n",
    "                                   gamma2=gamma2,\n",
    "                                   W_tilde=W_tilde,\n",
    "                                   Y_tilde=Y_tilde,\n",
    "                                   estimator_beta_tilde=estimator_beta_tilde, \n",
    "                                   T=T,\n",
    "                                   n_variables=1,\n",
    "                                   n_iter=1000)\n",
    "\n",
    "print(sample_posterior_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Draw from the conditional posterior of $\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sigma2_posterior(Y_tilde, estimator_beta_tilde, X_tilde, gamma2, T, n_variables, seed):\n",
    "    \"\"\"Sample random variables sigma^2|Y, U, X, ϕ, R2, q, z\n",
    "\n",
    "    Args:\n",
    "        Y_tilde (np.array): 1*T \\Tilde{Y} matrix\n",
    "        estimator_beta_tilde (np.array): 1*s(z) \\hat{\\Tilde{\\beta}} vector\n",
    "        X_tilde (np.array): T*s(z) \\Tilde{X} matrix\n",
    "        gamma2 (float): gamma^2 variable\n",
    "        T (int): number of samples\n",
    "        n_variables (int): number of variables desired\n",
    "        seed (int): seed\n",
    "\n",
    "    Returns:\n",
    "        _type_: n_variables sigma^2|Y, U, X, ϕ, R2, q, z\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    I_s_z=np.identity(X_tilde.shape[1])\n",
    "    inverse_gamma_dist = sp.stats.invgamma(T/2, scale=0.5*(Y_tilde.T@Y_tilde-estimator_beta_tilde.T@(X_tilde.T@X_tilde+(1/gamma2)*I_s_z)@estimator_beta_tilde))\n",
    "    return inverse_gamma_dist.rvs(size=n_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81758.34021657 85536.60018476]\n"
     ]
    }
   ],
   "source": [
    "array_sigma2_posterior=sample_sigma2_posterior(Y_tilde=Y_tilde,\n",
    "                                               estimator_beta_tilde=estimator_beta_tilde,\n",
    "                                               X_tilde=X_tilde,\n",
    "                                               gamma2=gamma2,\n",
    "                                               T=T,\n",
    "                                               n_variables=2,\n",
    "                                               seed=seed)\n",
    "print(array_sigma2_posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Draw from the conditional posterior of $\\tilde{\\beta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_beta_tilde_posterior(X_tilde, Y, U, phi, sigma2, gamma2, n_variables, seed):\n",
    "    \"\"\"Sample 1*s(z) random vectors \\tilde{β}|Y, U, X, ϕ, R2, q, sigma^2, z\n",
    "\n",
    "    Args:\n",
    "        X_tilde (np.array): T*s(z) \\Tilde{X} matrix\n",
    "        Y (np.array): T*1 vector of target\n",
    "        U (np.array): T*l matrix of predictors\n",
    "        phi (np.array): 1*l phi vector\n",
    "        sigma2 (float): sigma^2\n",
    "        gamma2 (float): gamma^2\n",
    "        n_variables (int): number of variables\n",
    "        seed (int): seed\n",
    "\n",
    "    Returns:\n",
    "        _type_: n_variables of 1*l random vectors\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    I_s_z=np.identity(X_tilde.shape[1])\n",
    "    if U==0:\n",
    "        return np.random.multivariate_normal(np.linalg.inv((1/gamma2)*I_s_z+X_tilde.T@X_tilde)@X_tilde.T@Y,sigma2*np.linalg.inv((1/gamma2)*I_s_z+X_tilde.T@X_tilde), n_variables)\n",
    "    else:\n",
    "        return np.random.multivariate_normal(np.linalg.inv((1/gamma2)*I_s_z+X_tilde.T@X_tilde)@X_tilde.T@(Y-U@phi),sigma2*np.linalg.inv((1/gamma2)*I_s_z+X_tilde.T@X_tilde), n_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.95008323  -9.25414079  -5.69520608  -1.42845618  -5.62275484]\n",
      " [ -3.15195418 -11.60255837  -2.3262441   -7.12269525  -8.02888534]]\n"
     ]
    }
   ],
   "source": [
    "array_beta_tilde_posterior=sample_beta_tilde_posterior(X_tilde=X_tilde,\n",
    "                                                       Y=Y,\n",
    "                                                       U=U,\n",
    "                                                       phi=phi,\n",
    "                                                       sigma2=sigma2,\n",
    "                                                       gamma2=gamma2,\n",
    "                                                       n_variables=2,\n",
    "                                                       seed=seed)\n",
    "\n",
    "print(array_beta_tilde_posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $l=0$ dans l'énoncé donc, $U=0$: bizarre comme certaines variances dépendent de U (celle du posterior de $\\phi$) et valent donc 0\n",
    "* Doute sur la génération de $\\beta$ et $Z$: en théorie $\\beta$, suit un mélange de lois (gaussien + dirac). Or, dans l'énoncé on demande explicitement de mettre $k-s$ élements de $\\beta$ à 0 et les autres composantes suivent une normale centrée réduite. De plus, $Z_j$ suit une loi de bernouilli de param_tre $q$. Or, dans ce cas, il n'y a pas de simulation aléatoire de $Z$. On regarde juste les composantes de $\\beta$ non-nulles. Je trouve ça étrange."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
